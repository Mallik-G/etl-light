
// THIS IS AN EXAMPLE CONFIGURATION

spark {
  app-name = "masterdata-etl"
  conf {
    spark.executor.memory = "1g"
    spark.eventLog.enabled = "true"
    spark.eventLog.dir = "hdfs:/user/spark/applicationHistory"
    spark.ui.port = "4045"
    spark.driver.extraJavaOptions = "-DSPARK_YARN_MODE=true"
    spark.task.maxFailures = "4"
  }
}

kafka {
  topics = ["events"]
  conf {
    group.id = "masterdata.etl"
    metadata.broker.list = "stress1-hadoop-dn-1.openstacklocal:9092"
    auto.offset.reset = "smallest"
  }
}

etl {

  lock {
    enabled = false
    zookeeper-connect = "stress1-hadoop-dn-1.openstacklocal:2181"
    path = "/etl/file.lock"
    wait-for-lock-seconds = 10
  }

  state {
    folder = "/data/etl/work/state"
    files-to-keep = 10
  }

  errors-folder = "/data/etl/errors/events"

  transformer = {
    class = ""
    config = {
    }
  }

  writer = {
    class = "yamrcraft.etlight.writers.TimePartitionedEventsWriter"
    config = {
      working-folder = "/data/etl/work/.staging/events"
      output-folder = "/data/etl/output/events"
      partition {
        field = "eventTime"
        pattern = "YYYY/MM/dd/HH"
      }
      type-to-folders-mapping {
        UserGameEvent = "games"
        UserSessionEvent = "sessions"
        UserProfileEvent = "users"
        UserManagementEvent = "users"
        UserFinancialEvent = "financials"
        AdminEvent = "admins"
        AdminSessionEvent = "admins"
        EntityEvent = "entities"
      }
    }
  }

}